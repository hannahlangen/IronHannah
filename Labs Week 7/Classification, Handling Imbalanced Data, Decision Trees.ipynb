{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477e8d60",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01cb8b",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You are working as an analyst with this internet service provider. You are provided with this historical data about your company's customers and their churn trends. Your task is to build a machine learning model that will help the company identify customers that are more likely to default/churn and thus prevent losses from such customers.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "In this lab, we will first take a look at the degree of imbalance in the data and correct it using the techniques we learned on the class.\n",
    "\n",
    "Here is the list of steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "- Import the required libraries and modules that you would need.\n",
    "- Read that data into Python and call the dataframe churnData.\n",
    "- Check the datatypes of all the columns in the data. You would see that the column TotalCharges is object type. Convert this column into numeric type using pd.to_numeric function.\n",
    "- Check for null values in the dataframe. Replace the null values.\n",
    "- Use the following features: tenure, SeniorCitizen, MonthlyCharges and TotalCharges:\n",
    "- Scale the features either by using normalizer or a standard scaler.\n",
    "- Split the data into a training set and a test set.\n",
    "- Fit a logistic Regression model on the training data.\n",
    "- Fit a Knn Classifier model on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd6a35",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec03f2",
   "metadata": {},
   "source": [
    "### Loading a dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "churnData = pd.read_csv(\"DATA_Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65098392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data types for all columns\n",
    "churnData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"TotalCharges\" to numeric using pd.to_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571da68",
   "metadata": {},
   "source": [
    "pd.get_dummies(churnData[\"Contract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58121d",
   "metadata": {},
   "source": [
    "churnData[\"TotalCharges\"] = pd.to_numeric(churnData[\"TotalCharges\"], errors='coerce')\n",
    "churnData.dtypes\n",
    "\n",
    "#check for and replace null values \n",
    "churnData.dropna(inplace=True)\n",
    "\n",
    "#scale features by using normalizer or a standard scaler:  tenure, SeniorCitizen, MonthlyCharges and TotalCharges\n",
    "#churnData = churnData[[\"tenure\",\"SeniorCitizen\",\"MonthlyCharges\",\"TotalCharges\",\"Churn\"]]\n",
    "\n",
    "#convert values to 0 and 1\n",
    "def x_y_to_1_0(value:[str]=None, x=\"Yes\", y=\"No\"):\n",
    "    if value == x:\n",
    "        return 1\n",
    "    elif value == y:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "churnData[\"Churn\"] = list(map(x_y_to_1_0, churnData[\"Churn\"]))\n",
    "churnData[\"Partner\"] = list(map(x_y_to_1_0, churnData[\"Partner\"]))\n",
    "churnData[\"Dependents\"] = list(map(x_y_to_1_0, churnData[\"Dependents\"]))\n",
    "churnData[\"PhoneService\"] = list(map(x_y_to_1_0, churnData[\"PhoneService\"]))\n",
    "churnData[\"OnlineSecurity\"] = list(map(x_y_to_1_0, churnData[\"OnlineSecurity\"]))\n",
    "churnData[\"OnlineBackup\"] = list(map(x_y_to_1_0, churnData[\"OnlineBackup\"]))\n",
    "churnData[\"DeviceProtection\"] = list(map(x_y_to_1_0, churnData[\"DeviceProtection\"]))\n",
    "churnData[\"TechSupport\"] = list(map(x_y_to_1_0, churnData[\"TechSupport\"]))\n",
    "churnData[\"StreamingTV\"] = list(map(x_y_to_1_0, churnData[\"StreamingTV\"]))\n",
    "churnData[\"StreamingMovies\"] = list(map(x_y_to_1_0, churnData[\"StreamingMovies\"]))\n",
    "\n",
    "def gender_conv(value:[str]=None, x=\"Female\", y=\"Male\"):\n",
    "    if value == x:\n",
    "        return 1\n",
    "    elif value == y:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "churnData[\"gender\"] = list(map(gender_conv, churnData[\"gender\"]))\n",
    "\n",
    "#def contract_conv(value:[str]=None, x=\"Month-to-month\", y=\"One year\"):\n",
    "    #if value == x:\n",
    "        #return 1\n",
    "    #elif value == y:\n",
    "      #  return 0\n",
    "   # else:\n",
    "        #return 2\n",
    "\n",
    "#churnData[\"Contract\"] = list(map(contract_conv, churnData[\"Contract\"]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_features= churnData.select_dtypes(\"object\")\n",
    "cat_cols=pd.get_dummies(categoricals_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData.dropna(inplace=True)\n",
    "\n",
    "#X/Y split\n",
    "X=churnData.drop(\"Churn\", axis=1)\n",
    "y=churnData[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3670df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X._get_numeric_data()\n",
    "X = pd.concat([X,cat_cols],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2fc84c",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66146055",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797addf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "log_model = LogisticRegression() \n",
    "\n",
    "#Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\n",
    "\n",
    "\n",
    "trans = PowerTransformer()\n",
    "\n",
    "trans.fit(X_train)\n",
    "\n",
    "X_train_mod = trans.transform(X_train)\n",
    "X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "log_model.fit(X_train_mod, y_train)\n",
    "\n",
    "y_pred_train_log = log_model.predict(X_train_mod)\n",
    "y_pred_test_log = log_model.predict(X_test_mod)\n",
    "\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log,pos_label=\"Yes\"),\n",
    "                                         recall_score(y_train, y_pred_train_log,pos_label=\"Yes\")],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log,pos_label=\"Yes\"),\n",
    "                                        recall_score(y_test, y_pred_test_log,pos_label=\"Yes\")]})\n",
    "\n",
    "display(performance_log)\n",
    "\n",
    "print(\"Confusion matrix for the train set\")\n",
    "print(confusion_matrix(y_train,y_pred_train_log))\n",
    "plot_confusion_matrix(log_model,X_train_mod,y_train, values_format = 'd')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_pred_test_log))\n",
    "plot_confusion_matrix(log_model,X_test_mod,y_test, values_format = 'd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b039495",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f404642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "#Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\n",
    "\n",
    "\n",
    "trans = PowerTransformer()\n",
    "\n",
    "trans.fit(X_train)\n",
    "\n",
    "X_train_mod = trans.transform(X_train)\n",
    "X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "knn_model.fit(X_train_mod, y_train)\n",
    "\n",
    "y_pred_train_log = knn_model.predict(X_train_mod)\n",
    "y_pred_test_log = knn_model.predict(X_test_mod)\n",
    "\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log,pos_label=\"Yes\"),\n",
    "                                         recall_score(y_train, y_pred_train_log,pos_label=\"Yes\")],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log,pos_label=\"Yes\"),\n",
    "                                        recall_score(y_test, y_pred_test_log,pos_label=\"Yes\")]})\n",
    "\n",
    "display(performance_log)\n",
    "\n",
    "print(\"Confusion matrix for the train set\")\n",
    "print(confusion_matrix(y_train,y_pred_train_log))\n",
    "plot_confusion_matrix(knn_model,X_train_mod,y_train, values_format = 'd')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_pred_test_log))\n",
    "plot_confusion_matrix(knn_model,X_test_mod,y_test, values_format = 'd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715f679",
   "metadata": {},
   "source": [
    "- Fit a Decision Tree Classifier on the training data.\n",
    "- Check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb607881",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=11)\n",
    "\n",
    "# Bear in mind that sklearn uses a different function for decision trees used for \n",
    "# classification ( to predict a categorical feature ): DecisionTreeClassifier() \n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_dt = dt.predict(X_train)\n",
    "y_pred_test_dt = dt.predict(X_test)\n",
    "\n",
    "\n",
    "performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_dt),\n",
    "                                         precision_score(y_train, y_pred_train_dt, pos_label=\"Yes\"),\n",
    "                                         recall_score(y_train, y_pred_train_dt, pos_label=\"Yes\")],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_dt),\n",
    "                                        precision_score(y_test, y_pred_test_dt, pos_label=\"Yes\"),\n",
    "                                        recall_score(y_test, y_pred_test_dt, pos_label=\"Yes\")]})\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "print(\"Confusion matrix for the train set\")\n",
    "print(confusion_matrix(y_train,y_pred_train_dt).T)\n",
    "plot_confusion_matrix(dt,X_train,y_train, values_format = 'd')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test,y_pred_test_dt).T)\n",
    "plot_confusion_matrix(dt,X_test,y_test, values_format = 'd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0aec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (34,20))\n",
    "\n",
    "plot_tree(dt,filled = True, rounded=True,feature_names=X.columns)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5aa6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
